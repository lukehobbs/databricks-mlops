name: Run a notebook in databricks on every commit, creating a new experiment run

on:
  push:
    branches: [ "main" ]
  workflow_dispatch:

jobs:
  run-databricks-notebook:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v2
      - name: Run a databricks notebook
        uses: databricks/run-notebook@v0
        with:
          local-notebook-path: MLFlow_Train.ipynb
          databricks-host: ${{ vars.DATABRICKS_HOST }}
          databricks-token: ${{ secrets.DATABRICKS_TOKEN }}
          git-commit: ${{ github.event.pull_request.head.sha || github.sha }}
          new-cluster-json: >
            {
              "num_workers": 1,
              "spark_version": "13.0.x-cpu-ml-scala2.12",
              "node_type_id": "i3.xlarge",
              "spark_env_vars": {
                "PYSPARK_PYTHON": "/databricks/python3/bin/python3",
                "DATABRICKS_USERNAME": "${{ vars.DATABRICKS_USERNAME }}"
              }
            }